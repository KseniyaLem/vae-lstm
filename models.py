# -*- coding: utf-8 -*-
"""models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I_9ao_ozQa9_6aQBrJXLEpo2kPxQ1YKp
"""

class VAEmodel(nn.Module):
    def __init__(self, config):
        super(VAEmodel, self).__init__()
        
        self.config = config
        #self.init_global_step()
        #self.init_cur_epoch()
        self.two_pi = torch.tensor(2 * np.pi)
        
        self.C = 1 # self.config['n_channel'] 
        self.WIN = 48 # self.config['l_win'] 
        self.H = 512 # self.config['num_hidden_units'] 
        self.input_dims = self.WIN * self.C # 48

        self.build_model()
        self.sigma()
        # self.define_loss()

    
    def forward(self, x):
        # print('ENCODER')
        h, z, mu, std = self.encoder(x)
        # print('DECODER')
        output = self.decoder(z)
        return output, h, mu, std 
    
    def sigma(self):
        sigma = torch.Tensor([self.config['sigma']])
        self.sigma2_offset = torch.Tensor([self.config['sigma2_offset']])
        self.sigma2 = torch.square(sigma)
        self.sigma2 = self.sigma2 + self.sigma2_offset
    
    def define_loss(self, input, output, mu, gamma):
    #   KL divergence loss - analytical result
        KL_loss = 0.5 * (torch.sum(torch.square(mu), 1)
                          + torch.sum(torch.square(gamma), 1)
                          - torch.sum(torch.log(torch.square(gamma)), 1)
                          - self.config['code_size'])
        KL_loss = torch.mean(KL_loss)

    #   norm 1 of standard deviation of the sample-wise encoder prediction
        std_dev_norm = torch.mean(gamma, axis=0)

        weighted_reconstruction_error_dataset = torch.sum(torch.square(input - output), [1, 2])       #self.original_siglal == input?? self.decoded == output
        weighted_reconstruction_error_dataset = torch.mean(weighted_reconstruction_error_dataset)
        weighted_reconstruction_error_dataset = weighted_reconstruction_error_dataset / (2 * self.sigma2)

    #   least squared reconstruction error
        ls_reconstruction_error = torch.sum(torch.square(input - output), [1, 2])
        ls_reconstruction_error = torch.mean(ls_reconstruction_error)

    #   sigma regularisor - input elbo
        sigma_regularisor_dataset = self.input_dims / 2 * torch.log(self.sigma2)
        two_pi = self.input_dims / 2 * torch.Tensor([2 * np.pi])
        elbo_loss = two_pi + sigma_regularisor_dataset + 0.5 * weighted_reconstruction_error_dataset + KL_loss
        
        return elbo_loss

    
    def reparameterize(self, mu, gamma):  
        std = torch.exp(0.5 * gamma)
        eps = torch.randn_like(std)   
        z = eps.mul(std).add(mu)
        return  z
    
    # DEL
    # def loss_function(self, input, output, mu, gamma, batch_size): 
    #     #BCE = F.binary_cross_entropy(output, input, reduction='sum')
    #     loss = nn.MSELoss()          
    #     BCE = loss(output, input)
        
    #     KLD = -0.5 * torch.sum(1 + gamma - mu.pow(2) - gamma.exp())  
    #     return BCE + KLD
        
    def encoder(self, x, lstm=False): 

        if lstm:
        # 32,1,48 - N,C_in,H / (32,48,1,1 - tf: input_tensor N,H,W,C)    
        # print(x.shape)                   #torch.Size([32, 48, 1, 1])
          x = x.view(12, 1, -1).float()
          # print(x.shape)                   #torch.Size([32, 1, 48])
        else:
          x = x.view(32, 1, -1).float()
        x = F.leaky_relu(self.conv_1(x)) # tf: 32, 24, 1, 32  
        # print(x.shape)                   #torch.Size([32, 32, 24])
        x = F.leaky_relu(self.conv_2(x)) # tf: 32, 12, 1, 64
        # print(x.shape)                   #torch.Size([32, 64, 12])
        x = F.leaky_relu(self.conv_3(x)) # tf: 32, 6, 1, 128
        # print(x.shape)                   #torch.Size([32, 128, 6])
        x = F.leaky_relu(self.conv_4(x)) # tf: 32, 1, 1, 512
        # print(x.shape)                   #torch.Size([32, 512, 1])
        h = torch.squeeze(x)             # tf: 32, 512 # Flatten            
        x = F.leaky_relu(self.fc_5(h))   # tf: 32, 24 # Dense
        # print(x.shape)                   #torch.Size([32, 24])
        mu = self.fc_mu(x)       # tf: 32, 6 # code_mean
        std = F.relu(self.fc_std(x))     # tf: 32, 6 # code_std

        # DEL
        z = self.reparameterize(mu, std)

        return h, z, mu, std
    
    def decoder(self, x): # 32, 6

        x = F.leaky_relu(self.fc_1(x)) # tf: 32, 512
        # print(x.shape)                 #torch.Size([32, 512])
        x = x.view(-1, 512, 1)         # tf: 32, 1, 1, 512
        # print(x.shape)                 #torch.Size([32, 512, 1])
        x = F.leaky_relu(self.dec_2(x))# tf: 32, 3, 1, 256
        # print(x.shape)                 #torch.Size([32, 768, 1])
        x = x.view(-1, 256, 3)
        # print(x.shape)                 #torch.Size([32, 256, 3])
        x = F.leaky_relu(self.dec_3(x))# tf: 32, 6, 1, 128
        # print(x.shape)                 #torch.Size([32, 256, 3])
        x = x.view(-1, 128, 6)
        # print(x.shape)                 #torch.Size([32, 128, 6])
        # depth_to_space
        x = F.leaky_relu(self.dec_4(x))# tf: 32, 24, 1, 32
        # print(x.shape)                 #torch.Size([32, 128, 6])
        x = x.view(-1, 32, 24)    
        # print(x.shape)                 #torch.Size([32, 32, 24])  
        # depth_to_space 
        x = F.leaky_relu(self.dec_5(x))# tf: 32, 48, 1, 16
        # print(x.shape)                 #torch.Size([32, 32, 24])
        x = x.view(-1, 16, 48)   
        # print(x.shape)                 #torch.Size([32, 16, 48])  
        # depth_to_space
        x = F.leaky_relu(self.dec_6(x))# tf: 32,48,1,1      
        # print(x.shape)                 #torch.Size([32, 1, 48])
        # sigma, sigma2
        return x
    
    def build_model(self):

        # SAME: padding = 1, VALID: padding = 0                
        #in_channels, out_channels, kernel_size, stride, padding
        self.conv_1 = nn.Conv1d(1, 32, 3, stride=2, padding=1)   
        self.conv_2 = nn.Conv1d(32, 64, 3, stride=2, padding=1)
        self.conv_3 = nn.Conv1d(64, 128, 3, stride=2, padding=1)
        self.conv_4 = nn.Conv1d(128, 512, 6, stride=1, padding=0)
        self.fc_5 = nn.Linear(512, 24)
        self.fc_mu = nn.Linear(24, 6)
        self.fc_std = nn.Linear(24, 6)
        self.fc_1 = nn.Linear(6, 512)  
        self.dec_2 = nn.ConvTranspose1d(512, 768, 1, stride=1, padding=0) # tf: 32,3,1,256       
        self.dec_3 = nn.ConvTranspose1d(256, 256, 3, stride=1, padding=1) # tf: 32,6,1,128
        self.dec_4 = nn.ConvTranspose1d(128, 128, 3, stride=1, padding=1) # tf: 32,24,1,32
        self.dec_5 = nn.ConvTranspose1d(32, 32, 3, stride=1, padding=1) # tf: 32,48,1,16
        self.dec_6 = nn.ConvTranspose1d(16, 1, 3, stride=1, padding=1) # tf: 32,48,1,1        



class LSTMmodel(nn.Module):

  def __init__(self, config):

    super(LSTMmodel, self).__init__()

    self.LSTM1 = nn.LSTM(input_size = config['code_size'], hidden_size = config['num_hidden_units_lstm'], batch_first = True) 
    self.LSTM2 = nn.LSTM(input_size = config['num_hidden_units_lstm'], hidden_size = config['num_hidden_units_lstm'], batch_first = True)
    self.LSTM3 = nn.LSTM(input_size = config['num_hidden_units_lstm'], hidden_size = config['code_size'], batch_first = True)
    self.linear = nn.Linear(6, 6)
    # self.hid_state = torch.zeros(1,32,config['num_hidden_units_lstm'])
    # self.memory_cell = torch.zeros(1,32, config['num_hidden_units_lstm'])

  def forward(self, x):
    output, (hid_state, memory_cell) = self.LSTM1(x)   #hid_state tensor containing the hidden state and  memory_cell tensor containing the cell state
    # print(hid_state.shape)
    output, (hid_state, memory_cell) = self.LSTM2(output)
    output, (hid_state, memory_cell) = self.LSTM3(output)
    out = self.linear(output)
    return out, (hid_state, memory_cell)


  def produce_embeddings(self, config, model_vae, data):
    embedding_lstm_train = np.zeros((data.n_train_lstm, config['l_seq'], config['code_size']))
    # print(data.n_train_lstm)
    # print(embedding_lstm_train.shape)
    for i in range(data.n_train_lstm):
      # print(data.train_set_lstm['data'][i].shape)
      input = torch.from_numpy(data.train_set_lstm['data'][i])
      # print(input.shape)
      h, z, mu, std = model_vae.encoder(input, lstm=True)
      code_mean = mu.detach().numpy()
      embedding_lstm_train[i] = code_mean
    x_train = embedding_lstm_train[:, :configurations['l_seq'] - 11]
    y_train = embedding_lstm_train[:, 1:]


    embedding_lstm_test = np.zeros((data.n_train_lstm, config['l_seq'], config['code_size']))
    # print(embedding_lstm_train.shape)
    for i in range(data.n_val_lstm):
      input = torch.from_numpy(data.val_set_lstm['data'][i])
      h, z, mu, std = model_vae.encoder(input, lstm=True)
      code_mean = mu.detach().numpy()
      embedding_lstm_test[i] = code_mean
    x_test = embedding_lstm_test[:, :config['l_seq'] - 1]
    y_test = embedding_lstm_test[:, 1:]
    return x_train, y_train, x_test, y_test