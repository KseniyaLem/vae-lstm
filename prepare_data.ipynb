{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prepare data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilbt3ThnioVO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScUmWceNybJb"
      },
      "source": [
        "def prep_data(dataset, config_ts):\n",
        "    idx_anomaly = []\n",
        "    for lib in config_ts['annomalies']:\n",
        "        for key, value in lib.items():\n",
        "            if key == 'position':\n",
        "                idx_anomaly.append(value)\n",
        "    t_unit = 'buisness_day'\n",
        "    t = []\n",
        "    readings = []\n",
        "    i = 0\n",
        "    \n",
        "    for index, row in dataset.iterrows():\n",
        "        if i > 0:\n",
        "            t.append(i)\n",
        "            readings.append(float(row))\n",
        "        i = i + 1\n",
        "    t = np.asarray(t)\n",
        "    readings = np.asarray(readings)\n",
        "    \n",
        "    return t, t_unit, readings, idx_anomaly"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzoPFEIkifrp"
      },
      "source": [
        "def process_and_save_specified_dataset(config_ts, dataset, idx_split, y_scale=5, save_file=False):\n",
        "    t, t_unit, readings, idx_anomaly = prep_data(dataset, config_ts)\n",
        "    \n",
        "    # split into training and test sets\n",
        "    training = readings[idx_split[0]:idx_split[1]]\n",
        "    t_train = t[idx_split[0]:idx_split[1]]\n",
        "    \n",
        "    # normalise by training mean and std \n",
        "    train_m = np.mean(training)\n",
        "    train_std = np.std(training)\n",
        "    print(\"\\nTraining set mean is {}\".format(train_m))\n",
        "    print(\"Training set std is {}\".format(train_std))\n",
        "    readings_normalised = (readings - train_m) / train_std\n",
        "    \n",
        "    training = readings_normalised[idx_split[0]:idx_split[1]]\n",
        "    if idx_split[0] == 0:\n",
        "        test = readings_normalised[idx_split[1]:]\n",
        "        t_test = t[idx_split[1]:] - idx_split[1]\n",
        "        idx_anomaly_test = np.asarray(idx_anomaly) - idx_split[1]\n",
        "    else:\n",
        "        test = [readings_normalised[:idx_split[0]], readings_normalised[idx_split[1]:]]\n",
        "        t_test = [t[:idx_split[0]], t[idx_split[1]:] - idx_split[1]]\n",
        "        idx_anomaly_split = np.squeeze(np.argwhere(np.asarray(idx_anomaly)>idx_split[0]))\n",
        "        idx_anomaly_test = [np.asarray(idx_anomaly[:idx_anomaly_split[0]]), \n",
        "                            np.asarray(idx_anomaly[idx_anomaly_split[0]:]) - idx_split[1]]\n",
        "    idx_anomaly_f_test = []\n",
        "    for idx in idx_anomaly_test:\n",
        "        if idx > 0 :\n",
        "             idx_anomaly_f_test.append(idx)  \n",
        "    idx_anomaly_f_test = np.array(idx_anomaly_f_test)\n",
        "    print(\"Anomaly indices in the test set are {}\".format(idx_anomaly_f_test))\n",
        "\n",
        "    data = {}\n",
        "    data['t'] = t\n",
        "    data['t_unit'] = t_unit\n",
        "    data['readings'] = readings\n",
        "    data['idx_anomaly'] = idx_anomaly\n",
        "    data['idx_split'] = idx_split\n",
        "    data['training'] = training\n",
        "    data['test'] = test\n",
        "    data['train_m'] = train_m\n",
        "    data['train_std'] = train_std\n",
        "    data['t_train'] = t_train\n",
        "    data['t_test'] = t_test\n",
        "    data['idx_anomaly_test'] = idx_anomaly_f_test\n",
        "    \n",
        "    # plot the whole normalised sequence\n",
        "    fig, axs = plt.subplots(1, 1, figsize=(18, 4), edgecolor='k')\n",
        "    fig.subplots_adjust(hspace=.4, wspace=.4)\n",
        "    axs.plot(t, readings_normalised)\n",
        "    if idx_split[0] == 0:\n",
        "        axs.plot(idx_split[1]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'b--')\n",
        "    else:\n",
        "        for i in range(2):\n",
        "            axs.plot(idx_split[i]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'b--')\n",
        "    for j in range(len(idx_anomaly)):\n",
        "        axs.plot(idx_anomaly[j]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'r--')\n",
        "    axs.grid(True)\n",
        "    axs.set_xlim(0, len(t))\n",
        "    axs.set_ylim(-y_scale, y_scale)\n",
        "    axs.set_xlabel(\"timestamp (every {})\".format(t_unit))\n",
        "    axs.set_ylabel(\"normalised readings\")\n",
        "    axs.set_title(\"{} dataset\\n(normalised by train mean {:.2f} and std {:.2f})\".format(dataset, train_m, train_std))\n",
        "    axs.legend(('data', 'train test set split', 'anomalies'))\n",
        "    \n",
        "    return t, readings_normalised, data"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}